링크
[[1. Overview&IDEA]]
[[2. Problem &  PoC]]
[[3. DATA Design]]
[[4. Publisher]]
[[5. Database & logger]]
[[6. Visualization]]
[[7. ToBeContinue...?]]
### Conclusion

여기까지 왔다면 정말 많이 왔다.
데이터를 직접 생성해서 KAFKA 구축해주고 보내는 부분까지 확인을 했다.

![[5. Database & logger-2.png]]

결과적으로보면 이런 대시보드를 완성할 수 있었다. JAVA만 깔려있다면 어떤 ec2든 그라파나로 모니터링 할 수 있게 된것이다. 물론 kafka ip등 여러가변요소를 잡아줘야 하지만 결과적으로는 실시간으로 어디서 어떤 문제가 있는지를 무조건 확인할 수 있게 되었다.

실제로 스트레스 테스트를 해본결과 5초이내로 무조건 확인을 할 수 있게 되어서 조금 안심이 되는 느낌이 들기도 한다,

구조는 아래와 같다.
```
	              InFulxDB - Grafana
Node2 \              |         
Node1 -> Kafka -> Telegraf
Node3 /
```
위에 구조로 운영이 되며 추후 Haddop 노드들을 달아서 완성 시킬 계획이다. 지금은 Kafka, Telegraf,Grafana를 모니터링 하고 있고 한개의 ec2를 더 모니터링 하고 있다.

우선 이전에 KAFKA까지 정리가 되었으니 다음 InFluxDB를 한번 보자

### InfluxDB

문제 상황은 아래였다
1. Kafka에 적제된 message를 InfluxDB로 적재하고싶다.
2. Kafka에 message는 json으로 형식을 정리할 필요가 있다.

#### DB설치

기본적으로 document에 나와있는 것을 기준으로 작업했다.
https://www.influxdata.com/blog/getting-started-apache-kafka-influxdb/

##### 설치
https://docs.influxdata.com/influxdb/v2/install/ 
위에 url을 가지고 설치를 진행했는데 kafka로 단련된 나는 설치하는게 그리 어렵지 않았다.

```sh
# Ubuntu/Debian AMD64
curl -O https://dl.influxdata.com/influxdb/releases/influxdb2_2.7.5-1_amd64.deb
sudo dpkg -i influxdb2_2.7.5-1_amd64.deb
```
요런 코드로 deb를 받아주고 이를 설치해 준다.
##### 실행
```sh
sudo service influxdb start
```
요 코드로 실행을 해주면 된다. daemon으로 떠있어서 다른 작업을 하기에도 쉽다.
```text
● influxdb.service - InfluxDB is an open-source, distributed, time series database
   Loaded: loaded (/lib/systemd/system/influxdb.service; enabled; vendor preset: enable>
   Active: active (running)
```
성공적으로 실행이 되면 요런 로그가 남는다.

### GUI
실행을 하게되고 aws에서 인바운드 규칙에서 8086 포트(기본포트)를 "내IP"만 해줘도 좋고 전체 공개를 해서 url로 접근이 가능하게 한다.
```
{ip}:{port}
```
로 들어가게 되면 아래와 같은 화면이 나온다.
![[5. Database & logger-3.png]]
여기서 get started 클릭
![[5. Database & logger-4.png]]
요런 화면에서 하라는대로 지정해준다.
![[5. Database & logger-5.png]]
고럼 로그인 창이 나오고 로그인을 하면 일딴 ㅇㅋ!

그럼이제 Telegraf를 설정해 줘야 한다.
![[5. Database & logger-6.png]]
Load Data에서 오른쪽 위에 INFLUXDB OUTPUT PLUGIN을 누르면
![[5. Database & logger-7.png]]
요런 화면이 나오는데 이부분이 바로 Telegraf -> InfluxDB로 넘어오는 데이터들을 변환하고 어디에 어떻게 적재할 것인지 설정해 주는 부분이 된다.



요걸 고대로 복사해서 이제 Telegraf.conf에 넣어줘야한다. 그리고 튜토리얼을 보면 Kafka에 대한 설정도 나오는데 요두개를 설정해 줘야한다.

```
Kafka -> telegraf -> infulxdb
```
구조이기 떄문에 telegraf에서는 kafka에서 넘어오는 데이터에 대한 설정도, influxdb에 넣는 설정도 같이 해줘야 하기 때문이다. 

### Telegraf.config


읽는 사람의 편의를 위해서 조금 더 길게 써보면 저걸 고대로 복사해서 telegraf를 실행할 서버로온다. 서버도 좋고 influx와 같은 서버에서 실행해도 된다.

원래 길지만 조금 정리해보면 아래와 같다.
```bash
telegraf.conf
기억하자 경로는 /etc/telegraf 에다가 이 문서를 넣어줘야한다.
  [agent]
    hostname = "Cluster"


  [[outputs.influxdb_v2]]
  urls = ["http://{ip}:8086"]

  token = "$INFLUX_TOKEN"

  organization = "test"

  bucket = "ec2"
  
[[inputs.kafka_consumer]]
  ## Kafka brokers.
  brokers = ["{ip}:9092"]
  client_id = "test"
  ## Topics to consume.
  topics = ["testtopic"]

  ## When set this tag will be added to all metrics with the topic as the value.
  topic_tag = "test"
  max_message_len = 1000000
  data_format = "json"
  json_name_key= "ec2Number"
```

보면 
* agent
	* 현재 telegraf가 실행되고 있는 프로세스를 agent라고 부르고 global한 설정을 해준다.
	* 여러개의 설정이 있지만 딱 하나 hostname만 해주었다.
	* 기본 hostname은 ip인데 요게 보기 싫어서 cluster라고 명명했다.
* outputs.influxdb_v2
	* influxdb로 나가는 데이터들에 관련한 부분이다.
	* url : influxdb가 실행되고 있는 ip:port를 입력해준다.
	* token : influxdb에서는 보안을 위해 token을 발급하고 각 bucket에 대한 읽고 쓰는 권한을 부여한다. 요걸 기억하고 있다가 후에 INFLUX_TOKEN에 변수로 token을 넣어주고 export해주면 된다.
	* organization : 이부분은 본인의 프로젝트이름을 넣어주면 된다. 단 influxdb에 최초에 입력한 부분과 같아야 한다고 생각한다.(확인 필)
	* bucket : 데이터가 저장될 bucket이다. 다른 데이터베이스의 Databases와 비슷하다.
* inputs.kafka_consumer
	* 카파카로부터 들어오는 데이터들에 관한 부분이다.
	* brokers : 당연히 kafka server.properties에 설정한 advertiseLinstenr에 ip:port를 넣어줘야한다.
	* cliend_id : kafka를 하나의 client로 보고 이를 구분짓는 이름이다.
	* topics : 구독할 토픽인데 내가 짠 구조는 데이터 안에 구분자가 있기 때문에 하나의 토픽만을 사용했다.(구조에 따라 여러개를 넣을 수 있다.)
	* topic_tag : ~~이부분이 조금 애매한데 tag가 influxdb의 구조인지 아니면 colume과 같은 친구인지는 공부가 조금 필요하다~~
	* data_format에서 삽질을 좀 많이했는데 중요하다. 여기는 kafka에서 넘어오는 json이든 csv는 많은 데이터를 어떻게 변환할 껀지에 대한 부분이다.

### data_format

우선은 url부터 보자면
https://docs.influxdata.com/telegraf/v1/data_formats/input/json/
https://github.com/tidwall/gjson/blob/v1.7.5/SYNTAX.md#path-structure
https://github.com/influxdata/telegraf/tree/master/plugins/parsers/json_v2
이거 3개를 같이 봐야한다.

json을 어떻게 변환할 건지에 대해서 이야기하는 것들인데 GJSON이라는 프로토콜을 따르는 것같다. 이는 json구조에서 데이터의 path에 대해 정의해 놓은 부분이다.

우선 내 json구조를 보게된면 아래와 같다. topRateProcess는 parsing도 잘못되어있고 너무 많아서 우선 제외했다.
```json
{
//현재 노드이름
  "ec2Number": "telegraf",
//현재 노드의 cpu 사용량
  "cpu": {
    "system": 6.2,
    "user": 0
  },
  //현재 노드의 disk r/w
  "disk": {
    "write": 16,
    "read": 3.7
  },
  //현재 노드의 mem 사용량
  "mem": {
    "used": 364.1,
    "unused": 788.1
  },
  "topRateProcess": []
}
```

중요한건 influxdb에는 measurment라는 key와 같은 역할을 하는 객체가 있는데 이를 설정해 주지 않으면 kafka-consumer로 기본설정을 하게 된다. 이렇게 되면 구분자가 사라지면서 이게 telegraf에서 온거든 kafka에서 온거든 다 똑같게 들어가므로 로그가 합쳐지게 되는 썩을 결과가 된다....
![[5. Database & logger-8.png|center|500]]
해서 위에 3개의 url이 필요한 것이다. 
내가 적용한 부분만 보면 아래와 같다.

```toml
#config
[[inputs.file]]
  files = ["example"]
  json_name_key = "name"
  tag_keys = ["my_tag_1"]
  json_string_fields = ["b_my_field"]
  data_format = "json"
```

```json
//input
{
    "a": 5,
    "b": {
        "c": 6,
        "my_field": "description"
    },
    "my_tag_1": "foo",
    "name": "my_json"
}
```

```text
output
my_json,my_tag_1=foo a=5,b_c=6,b_my_field="description"
```

config를 보면 json_name_key가 name일 때 output이 my_json으로 들어간다. 해서 ec2Number가 key값인 내구조에서 위에 config처럼 설정해 주면 각기 다른 measurment로 들어가게 된다.

이후 다른 json은 계층구조가 생기면 "\_"를 구분자로해서 들어간다.
해서 들어간 데이터를 보면 아래와 같다.
![[5. Database & logger-9.png]]

요기까지 하게 되면 우선 influx까지 들어오게 될것이다. 

##### Token

메뉴에서 API Tokens를 들어가서 토큰을 발급하게되면 (물론 아래는 내께 아니라 document에 나온것)
아래 토큰을 발급해 준다. 요거 무조건 기억하고 있어야한다. grafana에서도 필요하니까!
![[5. Database & logger-10.png]]
```yaml
export INFLUX_TOKEN=_YOUR_INFLUXDB_TOKEN_
```
터미널에서 token을 환경변수로 등록해주면 conf에서 알아서 잡아온다.

#### Telegraf

설치는 아래와 같이 진행하면되고
```bash
sudo apt-get update 
sudo apt-get install telegraf
```
실행은 /etc/telegraf가서 실행하면된다!

```yaml
telegraf --config _YOUR_HOME_DIRECTORY_/influxgarden_integration/telegraf.conf
```

이제 Grafana 남았다!!!
-> 다음편에서 계속 